---
title: Logistic and Multinomial Logistic Regression
format: html
editor: visual
---

**Model: Regressing binary dependent variable, `DRINKING_D`, on the following binary and continuous predictors: `FATAL_OR_M`, `OVERTURNED`, `CELL_PHONE`, `SPEEDING`, `AGGRESSIVE`, `DRIVER1617`, `DRIVER65PLUS`, `PCTBACHMOR`, and `MEDHHINC`.**

Prior to running any of the analyses, be sure to set the working directory using the `setwd` command, install the relevant R packages using the `install.packages` command, and load the relevant packages using the `library` command.

```{r setup}
library(aod)
library(ggplot2)
library(rms)
library(gmodels)
library(nnet)
library(DAAG)
library(ROCR)
library(xtable)
library(kableExtra)
library(ROCR)

options(scipen = 999)
```

*2.* Import the file `logistic_regression.csv` into R using the `read.csv` command. Now, you are ready to do some exploratory analyses.

```{r load data}
cdc_data <- read.csv("data/logistic_regression.csv")

head(cdc_data)
```

*2.a.* Using the table and prop.table commands, tabulate the dependent variable, `DRINKING_D.`

```{r tabulate}
DRINKING_D.tab <- table(cdc_data$DRINKING_D)

prop.table(DRINKING_D.tab)
```

In your report, in addition to the counts that you can obtain with the table command, you will be asked to report the proportion of crashes that involved a drunk driver using the prop.table command as above.

*2.b.* Using the CrossTable command in the gmodels library, examine the cross-tabulations between the dependent variable, `DRINKING_D`, and the following binary predictor variables: `FATAL_OR_M`, `OVERTURNED`, `CELL_PHONE`, `SPEEDING`, `AGGRESSIVE`, `DRIVER1617`, and `DRIVER65PLUS`.

*2.b.i.* For the first predictor (`FATAL_OR_M`), record the number and percentage of 1-responses (i.e., fatalities or major injuries) for both categories of the variable `DRINKING_D`, as well as the total number of 1-responses (i.e., fatalities or major injuries) in the data set. That is, how many fatalities or major injuries were there when the driver wasnâ€™t inebriated, when the driver was inebriated, and altogether?

*2.b.ii.* Repeat step *2.b.i* above for the rest of the binary predictors.

```{r cross-tabulations}
# I made a function to loop through it so I don't have to do this 7 separate times.
# Create predictor vector.
predictors <- c(
  "FATAL_OR_M", "OVERTURNED", "CELL_PHONE",
  "SPEEDING", "AGGRESSIVE",
  "DRIVER1617", "DRIVER65PLUS"
  )

# Create an empty results dataframe.
binary_results <- data.frame(
  Predictor = character(),
  Drink0_Count_1 = numeric(),
  Drink1_Count_1 = numeric(),
  Total_1 = numeric(),
  ChiSq = numeric(),
  p_value = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each predictor.
for (var in predictors) {
  
  cat("=======================================================\n")
  cat("PREDICTOR:", var, "\n")

  # Build 2x2 table.
  tab <- table(cdc_data$DRINKING_D, cdc_data[[var]])
  print(tab)
  
  # Row percentages.
  cat("\nRow percentages (within DRINKING_D):\n")
  print(round(prop.table(tab, 1), 4))
  
  # Count the number of 1's.
  total_ones <- sum(cdc_data[[var]] == 1)
  cat("\nTotal number of", var, "= 1 in dataset:", total_ones, "\n")
  
  # Chi-square test.
  test <- chisq.test(tab, correct = FALSE)
  cat("\nChi-square statistic:", test$statistic,
      "\nDegrees of freedom:", test$parameter,
      "\np-value:", test$p.value, "\n")
  
  # Add row to results dataframe.
  binary_results <- rbind(
    binary_results,
    data.frame(
      Predictor = var,
      Drink0_Count_1 = tab["0", "1"],
      Drink1_Count_1 = tab["1", "1"],
      Total_1 = total_ones,
      ChiSq = unname(test$statistic),
      p_value = test$p.value
    )
  )
}
```

*2.b.iii.* In your report, you will be asked to present the cross-tabulations from *2.b.i* and *2.b.ii* in a table.

```{r 2.b.iii table}
# Build summary table.
binary_summary <- data.frame(
  Predictor = character(),
  DRINKING_D = integer(),
  Count_1 = integer(),
  Percent_1 = numeric(),
  Total_1 = integer(),
  stringsAsFactors = FALSE
)

for (var in predictors) {
  tab <- table(DRINKING_D = cdc_data$DRINKING_D,
               Predictor   = cdc_data[[var]])
  row_props <- prop.table(tab, 1)
  total_1 <- sum(tab[, "1"])

  for (d in rownames(tab)) {
    binary_summary <- rbind(
      binary_summary,
      data.frame(
        Predictor  = var,
        DRINKING_D = as.integer(d),
        Count_1    = as.integer(tab[d, "1"]),
        Percent_1  = 100 * as.numeric(row_props[d, "1"]),
        Total_1    = total_1
      )
    )
  }
}

binary_summary$DRINKING_D <- ifelse(
  binary_summary$DRINKING_D == 0, "No Alcohol", "Alcohol"
)

kable(binary_summary, digits = 2)
```

*2.b.iv.* Prior to doing predictive modeling, statisticians often use the Chi-Square (Ï‡2) test to determine whether the distribution of one categorical variable varies with respect to the values of another categorical variable. If we were to look at a cross-tabulation of the variables `DRINKING_D` and `FATAL_OR_M`, the null and alternative hypotheses for the Ï‡2 test would be as follows:

*H0:* The proportion of fatalities for crashes that involve drunk drivers is the same as the proportion of fatalities for crashes that donâ€™t involve drunk drivers.

vs.

*Ha:* The proportion of fatalities for crashes that involve drunk drivers is different than the proportion of fatalities for crashes that donâ€™t involve drunk drivers.

As usual, a high value of the Ï‡2 statistic, and a p-value lower than 0.05 suggest that thereâ€™s evidence to reject the null hypothesis in favor of the alternative, and that thereâ€™s an association between drunk driving and crash fatalities.

*2.b.iv.1.* To carry out the Ï‡2 test in R to test the hypothesis above, you would use the syntax `CrossTable(cdc_data$FATAL_OR_M, cdc_data$DRINKING_D, prop.r = FALSE, prop.t = FALSE, prop.chisq = FALSE, chisq = TRUE)`. The Ï‡2 results will appear below the cross-tabulation table that you have seen in *2.b.i* above. Report the results without the Yates Continuity Correction.

*2.b.iv.2.* Modifying the syntax in *2.b.iv.1* above, run the Ï‡2 test examining the association between the dependent variable and the remaining binary predictors.

```{r chi square tests}
chi_results <- data.frame(
  Predictor = predictors,
  Chi_sq = NA_real_,
  df = 1,
  p_value = NA_real_
)

for (i in seq_along(predictors)) {
  var <- predictors[i]
  tab <- table(cdc_data$DRINKING_D, cdc_data[[var]])
  test <- chisq.test(tab, correct = FALSE)
  chi_results$Chi_sq[i] <- test$statistic
  chi_results$p_value[i] <- test$p.value
}

kable(chi_results, digits = 4)
```

*2.b.iv.3.* In the table *2.b.iii* above, add another column called â€œÏ‡2 p-valueâ€. For each row, present the p-value from the corresponding Ï‡2 test.

```{r 2.b.iii summary}
binary_summary2 <- merge(binary_summary, chi_results, by = "Predictor")

kable(binary_summary2, digits = 3)
```

*2.b.iv.3.a.* Note, however, that in practice, statisticians generally present not just the p-value, but also the value of the Ï‡2 statistic and the degrees of freedom, which is the parameter of the Ï‡2 distribution. The degrees of freedom is calculated as (R âˆ’ 1)(C âˆ’ 1), where R is the number of rows in the cross-tabulation table and C is the number of columns in the cross-tabulation table. Said differently, R is the number of categories of the first variable and C is the number of categories in the second variable. Here, because we are cross-tabulating two binary variables, both R and C are 2, and df = (R âˆ’ 1)(C âˆ’ 1) = 1.

*2.c.* Now, letâ€™s examine whether the means of the two continuous predictors seem to differ for the different levels of the dependent variable. To do this, calculate the group means (and standard deviations) of both predictors (`PCTBACHMOR` and `MEDHHINC`) for crashes that involve drunk drivers and crashes that donâ€™t.

*2.c.i.* In order to do this in R, use the `tapply` command. For instance, if you want to calculate the average values of the variable `PCTBACHMOR` for crashes that involve drunk drivers and crashes that donâ€™t, you would use the following syntax: `tapply(cdc_data$PCTBACHMOR, cdc_data$DRINKING_D, mean)`. To calculate the standard deviations of the variable `PCTBACHMOR` for crashes that involve drunk drivers and crashes that donâ€™t, you would use the following syntax: `tapply(cdc_data$PCTBACHMOR, cdc_data$DRINKING_D, sd)`.

*2.c.ii.* Present your results in a table.

```{r means and SDs table}
continuous_vars <- c("PCTBACHMOR", "MEDHHINC")

mean_sd_table <- do.call(rbind, lapply(continuous_vars, function(v) {
  data.frame(
    Predictor = v,
    Group = c("No Alcohol", "Alcohol"),
    Mean = tapply(cdc_data[[v]], cdc_data$DRINKING_D, mean),
    SD = tapply(cdc_data[[v]], cdc_data$DRINKING_D, sd)
  )
}))

kable(mean_sd_table, digits = 2)
```

*2.c.iii.* Recall from introductory statistics classes that in order to compare the mean value of a continuous variable for two independent groups, statisticians usually employ a test thatâ€™s called the independent samples t-test. For example, we can see whether the average `PCTBACHMOR` values are statistically significantly different for crashes that involve drunk drivers and crashes that donâ€™t. The null and alternative hypotheses for the independent samples t-test would be as follows:

*H0:* average values of the variable `PCTBACHMOR` are the same for crashes that involve drunk drivers and crashes that donâ€™t.

vs.

*Ha:* average values of the variable `PCTBACHMOR` are different for crashes that involve drunk drivers and crashes that donâ€™t.

A high value of the t-statistic, and a p-value lower than 0.05 suggest that thereâ€™s evidence to reject the null hypothesis in favor of the alternative.

*2.c.iii.1.* To carry out the t-test in R to test the hypothesis above, you would use the syntax `t.test(mydata$PCTBACHMOR~mydata$DRINKING_D)`.

```{r t-tests}
t_PCTB <- t.test(cdc_data$PCTBACHMOR ~ cdc_data$DRINKING_D)
t_MEDH <- t.test(cdc_data$MEDHHINC ~ cdc_data$DRINKING_D)

t_table <- data.frame(
  Predictor = c("PCTBACHMOR", "MEDHHINC"),
  t_stat = c(t_PCTB$statistic, t_MEDH$statistic),
  df = c(t_PCTB$parameter, t_MEDH$parameter),
  p_value = c(t_PCTB$p.value, t_MEDH$p.value)
)

kable(t_table, digits = 4)
```

*2.c.iii.2.* Repeat the t-test for the variable `MEDHHINC.`

*2.c.iii.3.* In the table *2.c.ii* above, add another column called â€œt-test pvalueâ€. For each row, present the p-value from the corresponding t-test.

```{r t-test p-value}
mean_sd_table2 <- merge(mean_sd_table, t_table, by = "Predictor")

kable(mean_sd_table2, digits = 4)
```

*2.c.iii.3.a.* Note, however, that in practice, statisticians generally present not just the p-value, but also the value of the t-statistic and the degrees of freedom.

*2.d.* Using the instructions from Assignment 1, examine the Pearson correlations between all the predictors (both binary and continuous). Is there evidence of severe multicollinearity here? (Be sure the appropriate R library is loaded).

```{r pearson correlation}
all_predictors <- c(
  predictors,
  "PCTBACHMOR", "MEDHHINC"
)

corr_matrix <- cor(cdc_data[, all_predictors], use = "complete.obs")

kable(corr_matrix, digits = 3)
```

*3.* Now that weâ€™re done with exploratory analysis, we are ready to proceed to running the logistic regression.

*3.a.* Using the `glm` command for logistic regression (as shown in the slides), regress the `DRINKING_D` variable on the following predictors: `FATAL_OR_M`, `OVERTURNED`, `CELL_PHONE`, `SPEEDING`, `AGGRESSIVE`, `DRIVER1617`, `DRIVER65PLUS`, `PCTBACHMOR`, and `MEDHHINC`.

*3.a.i.* Use the summary command to examine the results.

```{r final model}
logit_full <- glm(DRINKING_D ~
                    FATAL_OR_M + OVERTURNED + CELL_PHONE +
                    SPEEDING + AGGRESSIVE + DRIVER1617 + DRIVER65PLUS +
                    PCTBACHMOR + MEDHHINC,
                  family = binomial,
                  data = cdc_data
                  )

summary(logit_full)
```

*3.a.ii.* For each predictor, also compute the odds ratio and the 95% confidence interval (CI) using commands shown in the slides. Use the syntax presented on the slide titled â€˜Merging Odds Ratios to ð›½ Coefficients in Râ€™ to merge the odds ratios and CIs to the matrix that contains coefficients and p-values. Present the resulting (merged) matrix in your report.

```{r odds ratios}
coefs <- summary(logit_full)$coefficients
OR <- exp(coef(logit_full))
lower <- exp(coef(logit_full) - 1.96 * coefs[, "Std. Error"])
upper <- exp(coef(logit_full) + 1.96 * coefs[, "Std. Error"])

merged <- cbind(coefs, OR, lower, upper)

kable(merged, digits = 3)
```

*3.a.iii.* Using the syntax presented in the slides, calculate the sensitivity, specificity and misclassification rate for each of the following cut-off values: **0.02; 0.03; 0.05; 0.07; 0.08; 0.09; 0.10; 0.15; 0.20; 0.50** and present them in a table. In the table, highlight the cut-off value which has the lowest misclassification rate.

```{r sensitivity specificity misclassification}
cutoffs <- c(0.02, 0.03, 0.05, 0.07, 0.08, 0.09, 0.10, 0.15, 0.20, 0.50)

phat <- logit_full$fitted.values
y <- cdc_data$DRINKING_D

cutoff_table <- data.frame(
  Cutoff = cutoffs,
  Sensitivity = NA,
  Specificity = NA,
  Misclass = NA
)

for (i in seq_along(cutoffs)) {
  
  c <- cutoffs[i]
  pred <- ifelse(phat >= c, 1, 0)
  
  TP <- sum(pred == 1 & y == 1)
  TN <- sum(pred == 0 & y == 0)
  FP <- sum(pred == 1 & y == 0)
  FN <- sum(pred == 0 & y == 1)
  
  cutoff_table$Sensitivity[i] <- TP/(TP+FN)
  cutoff_table$Specificity[i] <- TN/(TN+FP)
  cutoff_table$Misclass[i] <- (FP+FN)/length(y)
}

kable(
  cutoff_table,
  digits = 3,
  caption = "Sensitivity, Specificity, and Misclassification Across Cutoffs"
)
```

: Sensitivity, Specificity, and Misclassification Table

*3.a.iv.* Using the syntax presented in the slides, generate the ROC curve, and identify the optimal cut-off value. Be sure to export the image of the ROC curve (as you will be expected to present it in your report).

```{r ROC curve}
pred <- prediction(phat, y)
perf <- performance(pred, "tpr", "fpr")

plot(perf, main="ROC Curve")
abline(0,1,lty = 2)

auc_value <- performance(pred, "auc")@y.values[[1]]

auc_value
```

*3.a.v.* Using the syntax presented in the slides, calculate the area under the ROC curve.

*3.b.* Re-run the model without the `PCTBACHMOR` and `MEDHHINC` terms. As in *3.a.i* and *3.a.ii* above, use the summary command to examine results, and calculate the odds ratio and the 95% confidence interval for each predictor. As in *3.a.ii* above, merge the odds ratios and confidence intervals to the matrix containing coefficients and p-values. Present the resulting (merged) matrix in your report.

```{r}
logit_reduced <- glm(DRINKING_D ~
                       FATAL_OR_M + OVERTURNED + CELL_PHONE +
                       SPEEDING + AGGRESSIVE + DRIVER1617 + DRIVER65PLUS,
                     data = cdc_data,
                     family = binomial
                     )

summary(logit_reduced)

reduced_coefs <- summary(logit_reduced)$coefficients
OR2 <- exp(coef(logit_reduced))
CI2 <- exp(confint(logit_reduced))

reduced_logit_results <- cbind(
  reduced_coefs,
  OR = OR2,
  CI_low = CI2[,1],
  CI_high = CI2[,2]
)

kable(
  reduced_logit_results,
  digits = 3,
  caption="Reduced Logistic Model: Coefficients, OR, CI"
)
```

*3.c.* Compare the two models using the Akaike Information Criterion (AIC). The results are typically presented at the bottom of the logistic regression output. They may also be obtained using the `AIC` command. For instance, if the results obtained from the `glm` command for the first model are saved as `mylogit1` and the results from the second model are saved as `mylogit2`, the R syntax to obtain the AICs from both models would be `AIC(mylogit1, mylogit2)`. Here, recall that lower values of the AIC correspond to a better model.

```{r compare models}
AIC(logit_full, logit_reduced)
```
