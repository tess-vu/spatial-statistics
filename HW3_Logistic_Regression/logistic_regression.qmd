---
title: Logistic and Multinomial Logistic Regression
format: html
editor: visual
---

**Model: Regressing binary dependent variable, `DRINKING_D`, on the following binary and continuous predictors: `FATAL_OR_M`, `OVERTURNED`, `CELL_PHONE`, `SPEEDING`, `AGGRESSIVE`, `DRIVER1617`, `DRIVER65PLUS`, `PCTBACHMOR`, and `MEDHHINC`.**

Prior to running any of the analyses, be sure to set the working directory using the `setwd` command, install the relevant R packages using the `install.packages` command, and load the relevant packages using the `library` command.

```{r setup}
library(aod)
library(ggplot2)
library(rms)
library(gmodels)
library(nnet)
library(DAAG)
library(ROCR)
library(xtable)
library(kableExtra)
library(ROCR)

options(scipen = 999)
```

*2.* Import the file `logistic_regression.csv` into R using the `read.csv` command. Now, you are ready to do some exploratory analyses.

```{r load data}
cdc_data <- read.csv("data/logistic_regression.csv")

head(cdc_data)
```

*2.a.* Using the table and prop.table commands, tabulate the dependent variable, `DRINKING_D.`

```{r tabulate}
DRINKING_D.tab <- table(cdc_data$DRINKING_D)

prop.table(DRINKING_D.tab)
```

In your report, in addition to the counts that you can obtain with the table command, you will be asked to report the proportion of crashes that involved a drunk driver using the prop.table command as above.

*2.b.* Using the CrossTable command in the gmodels library, examine the cross-tabulations between the dependent variable, `DRINKING_D`, and the following binary predictor variables: `FATAL_OR_M`, `OVERTURNED`, `CELL_PHONE`, `SPEEDING`, `AGGRESSIVE`, `DRIVER1617`, and `DRIVER65PLUS`.

*2.b.i.* For the first predictor (`FATAL_OR_M`), record the number and percentage of 1-responses (i.e., fatalities or major injuries) for both categories of the variable `DRINKING_D`, as well as the total number of 1-responses (i.e., fatalities or major injuries) in the data set. That is, how many fatalities or major injuries were there when the driver wasnâ€™t inebriated, when the driver was inebriated, and altogether?

*2.b.ii.* Repeat step *2.b.i* above for the rest of the binary predictors.

```{r cross-tabulations}
# I made a function to loop through it so I don't have to do this 7 separate times.
# Create predictor vector.
predictors <- c(
  "FATAL_OR_M", "OVERTURNED", "CELL_PHONE",
  "SPEEDING", "AGGRESSIVE",
  "DRIVER1617", "DRIVER65PLUS"
  )

# Create an empty results dataframe.
binary_results <- data.frame(
  Predictor = character(),
  Drink0_Count_1 = numeric(),
  Drink1_Count_1 = numeric(),
  Total_1 = numeric(),
  ChiSq = numeric(),
  p_value = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each predictor.
for (var in predictors) {
  
  cat("=======================================================\n")
  cat("PREDICTOR:", var, "\n")

  # Build 2x2 table.
  tab <- table(cdc_data$DRINKING_D, cdc_data[[var]])
  print(tab)
  
  # Row percentages.
  cat("\nRow percentages (within DRINKING_D):\n")
  print(round(prop.table(tab, 1), 4))
  
  # Count the number of 1's.
  total_ones <- sum(cdc_data[[var]] == 1)
  cat("\nTotal number of", var, "= 1 in dataset:", total_ones, "\n")
  
  # Chi-square test.
  test <- chisq.test(tab, correct = FALSE)
  cat("\nChi-square statistic:", test$statistic,
      "\nDegrees of freedom:", test$parameter,
      "\np-value:", test$p.value, "\n")
  
  # Add row to results dataframe.
  binary_results <- rbind(
    binary_results,
    data.frame(
      Predictor = var,
      Drink0_Count_1 = tab["0", "1"],
      Drink1_Count_1 = tab["1", "1"],
      Total_1 = total_ones,
      ChiSq = unname(test$statistic),
      p_value = test$p.value
    )
  )
}
```

*2.b.iii.* In your report, you will be asked to present the cross-tabulations from *2.b.i* and *2.b.ii* in a table.

```{r 2.b.iii table}
# Build summary table.
binary_summary <- data.frame(
  Predictor = character(),
  DRINKING_D = integer(),
  Count_1 = integer(),
  Percent_1 = numeric(),
  Total_1 = integer(),
  stringsAsFactors = FALSE
)

for (var in predictors) {
  tab <- table(DRINKING_D = cdc_data$DRINKING_D,
               Predictor   = cdc_data[[var]])
  row_props <- prop.table(tab, 1)
  total_1 <- sum(tab[, "1"])

  for (d in rownames(tab)) {
    binary_summary <- rbind(
      binary_summary,
      data.frame(
        Predictor  = var,
        DRINKING_D = as.integer(d),
        Count_1    = as.integer(tab[d, "1"]),
        Percent_1  = 100 * as.numeric(row_props[d, "1"]),
        Total_1    = total_1
      )
    )
  }
}

binary_summary$DRINKING_D <- ifelse(
  binary_summary$DRINKING_D == 0, "No Alcohol", "Alcohol"
)

kable(binary_summary, digits = 2)
```

*2.b.iv.* Prior to doing predictive modeling, statisticians often use the Chi-Square (Ï‡2) test to determine whether the distribution of one categorical variable varies with respect to the values of another categorical variable. If we were to look at a cross-tabulation of the variables `DRINKING_D` and `FATAL_OR_M`, the null and alternative hypotheses for the Ï‡2 test would be as follows:

*H0:* The proportion of fatalities for crashes that involve drunk drivers is the same as the proportion of fatalities for crashes that donâ€™t involve drunk drivers.

vs.

*Ha:* The proportion of fatalities for crashes that involve drunk drivers is different than the proportion of fatalities for crashes that donâ€™t involve drunk drivers.

As usual, a high value of the Ï‡2 statistic, and a p-value lower than 0.05 suggest that thereâ€™s evidence to reject the null hypothesis in favor of the alternative, and that thereâ€™s an association between drunk driving and crash fatalities.

*2.b.iv.1.* To carry out the Ï‡2 test in R to test the hypothesis above, you would use the syntax `CrossTable(cdc_data$FATAL_OR_M, cdc_data$DRINKING_D, prop.r = FALSE, prop.t = FALSE, prop.chisq = FALSE, chisq = TRUE)`. The Ï‡2 results will appear below the cross-tabulation table that you have seen in *2.b.i* above. Report the results without the Yates Continuity Correction.

*2.b.iv.2.* Modifying the syntax in *2.b.iv.1* above, run the Ï‡2 test examining the association between the dependent variable and the remaining binary predictors.

```{r chi square tests}
chi_results <- data.frame(
  Predictor = predictors,
  Chi_sq = NA_real_,
  df = 1,
  p_value = NA_real_
)

for (i in seq_along(predictors)) {
  var <- predictors[i]
  tab <- table(cdc_data$DRINKING_D, cdc_data[[var]])
  test <- chisq.test(tab, correct = FALSE)
  chi_results$Chi_sq[i] <- test$statistic
  chi_results$p_value[i] <- test$p.value
}

kable(chi_results, digits = 4)
```

*2.b.iv.3.* In the table *2.b.iii* above, add another column called â€œÏ‡2 p-valueâ€. For each row, present the p-value from the corresponding Ï‡2 test.

```{r 2.b.iii summary}
binary_summary2 <- merge(binary_summary, chi_results, by = "Predictor")

kable(binary_summary2, digits = 3)
```

*2.b.iv.3.a.* Note, however, that in practice, statisticians generally present not just the p-value, but also the value of the Ï‡2 statistic and the degrees of freedom, which is the parameter of the Ï‡2 distribution. The degrees of freedom is calculated as (R âˆ’ 1)(C âˆ’ 1), where R is the number of rows in the cross-tabulation table and C is the number of columns in the cross-tabulation table. Said differently, R is the number of categories of the first variable and C is the number of categories in the second variable. Here, because we are cross-tabulating two binary variables, both R and C are 2, and df = (R âˆ’ 1)(C âˆ’ 1) = 1.

*2.c.* Now, letâ€™s examine whether the means of the two continuous predictors seem to differ for the different levels of the dependent variable. To do this, calculate the group means (and standard deviations) of both predictors (`PCTBACHMOR` and `MEDHHINC`) for crashes that involve drunk drivers and crashes that donâ€™t.

*2.c.i.* In order to do this in R, use the `tapply` command. For instance, if you want to calculate the average values of the variable `PCTBACHMOR` for crashes that involve drunk drivers and crashes that donâ€™t, you would use the following syntax: `tapply(cdc_data$PCTBACHMOR, cdc_data$DRINKING_D, mean)`. To calculate the standard deviations of the variable `PCTBACHMOR` for crashes that involve drunk drivers and crashes that donâ€™t, you would use the following syntax: `tapply(cdc_data$PCTBACHMOR, cdc_data$DRINKING_D, sd)`.

*2.c.ii.* Present your results in a table.

```{r means and SDs table}
continuous_vars <- c("PCTBACHMOR", "MEDHHINC")

mean_sd_table <- do.call(rbind, lapply(continuous_vars, function(v) {
  data.frame(
    Predictor = v,
    Group = c("No Alcohol", "Alcohol"),
    Mean = tapply(cdc_data[[v]], cdc_data$DRINKING_D, mean),
    SD = tapply(cdc_data[[v]], cdc_data$DRINKING_D, sd)
  )
}))

kable(mean_sd_table, digits = 2)
```

*2.c.iii.* Recall from introductory statistics classes that in order to compare the mean value of a continuous variable for two independent groups, statisticians usually employ a test thatâ€™s called the independent samples t-test. For example, we can see whether the average `PCTBACHMOR` values are statistically significantly different for crashes that involve drunk drivers and crashes that donâ€™t. The null and alternative hypotheses for the independent samples t-test would be as follows:

*H0:* average values of the variable `PCTBACHMOR` are the same for crashes that involve drunk drivers and crashes that donâ€™t.

vs.

*Ha:* average values of the variable `PCTBACHMOR` are different for crashes that involve drunk drivers and crashes that donâ€™t.

A high value of the t-statistic, and a p-value lower than 0.05 suggest that thereâ€™s evidence to reject the null hypothesis in favor of the alternative.

*2.c.iii.1.* To carry out the t-test in R to test the hypothesis above, you would use the syntax `t.test(mydata$PCTBACHMOR~mydata$DRINKING_D)`.

```{r t-tests}
t_PCTB <- t.test(cdc_data$PCTBACHMOR ~ cdc_data$DRINKING_D)
t_MEDH <- t.test(cdc_data$MEDHHINC ~ cdc_data$DRINKING_D)

t_table <- data.frame(
  Predictor = c("PCTBACHMOR", "MEDHHINC"),
  t_stat = c(t_PCTB$statistic, t_MEDH$statistic),
  df = c(t_PCTB$parameter, t_MEDH$parameter),
  p_value = c(t_PCTB$p.value, t_MEDH$p.value)
)

kable(t_table, digits = 4)
```

*2.c.iii.2.* Repeat the t-test for the variable `MEDHHINC.`

*2.c.iii.3.* In the table *2.c.ii* above, add another column called â€œt-test pvalueâ€. For each row, present the p-value from the corresponding t-test.

```{r t-test p-value}
mean_sd_table2 <- merge(mean_sd_table, t_table, by = "Predictor")

kable(mean_sd_table2, digits = 4)
```

*2.c.iii.3.a.* Note, however, that in practice, statisticians generally present not just the p-value, but also the value of the t-statistic and the degrees of freedom.

*2.d.* Using the instructions from Assignment 1, examine the Pearson correlations between all the predictors (both binary and continuous). Is there evidence of severe multicollinearity here? (Be sure the appropriate R library is loaded).

```{r pearson correlation}
#| fig-width: 6
#| fig-height: 6
#| fig-dpi: 300
# 1. Define all predictors (binary and continuous)
all_predictors <- c(
  predictors,
  "MEDHHINC",
  "PCTBACHMOR"
)

library(ggcorrplot)

# Calculate correlation matrix
corr_matrix <- cor(cdc_data[, all_predictors], use = "complete.obs")

# Create correlation plot
pearson_corr <- ggcorrplot(corr_matrix, 
           hc.order = TRUE,
           type = "lower",
           lab = TRUE,
           lab_size = 3,
           colors = c("#0072B2", "white", "#D55E00"),
           title = "Pearson Correlation Matrix of Predictors") +
  theme(
    axis.text.x = element_text(size = 8, angle = 45, hjust = 1),
    axis.text.y = element_text(size = 8),
    plot.title = element_text(hjust = 0.5, size = 12)
  )

pearson_corr

#ggsave("correlation_matrix.png", plot = pearson_corr, width = 6, height = 6, dpi = 300)
```

*3.* Now that weâ€™re done with exploratory analysis, we are ready to proceed to running the logistic regression.

*3.a.* Using the `glm` command for logistic regression (as shown in the slides), regress the `DRINKING_D` variable on the following predictors: `FATAL_OR_M`, `OVERTURNED`, `CELL_PHONE`, `SPEEDING`, `AGGRESSIVE`, `DRIVER1617`, `DRIVER65PLUS`, `PCTBACHMOR`, and `MEDHHINC`.

*3.a.i.* Use the summary command to examine the results.

```{r final model}
logit_full <- glm(DRINKING_D ~
                    FATAL_OR_M + OVERTURNED + CELL_PHONE +
                    SPEEDING + AGGRESSIVE + DRIVER1617 + DRIVER65PLUS +
                    PCTBACHMOR + MEDHHINC,
                  family = binomial,
                  data = cdc_data
                  )

summary(logit_full)

full_coefs <- summary(logit_full)$coefficients
OR2 <- exp(coef(logit_full))
CI2 <- exp(confint(logit_full))

full_logit_results <- cbind(
  full_coefs,
  OR = OR2,
  CI_low = CI2[,1],
  CI_high = CI2[,2]
)

# Create table.
full_model <- kbl(full_logit_results, 
    digits = 2,
    # Rename columns.
    col.names = c("Estimate", "Standard Error", "Z-Value", "P-Value", "Odds Ratio", "2.5% CI", "97.5% CI"),
    align = "c",
    caption = "Full Logistic Regression Model (Binary Predictors)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F) %>%
  column_spec(1, bold = T) %>%
  footnote(
    general = c(
      "<i>FATAL_OR_M:</i> Crash resulted in fatality or major injury.",
      "<i>OVERTURNED:</i> Crash involved an overturned vehicle.",
      "<i>CELL_PHONE:</i> Driver was using cell phone.",
      "<i>SPEEDING:</i> Crash involved speeding car.",
      "<i>AGGRESSIVE:</i> Crash involved aggressive driving.",
      "<i>DRIVER1617:</i> Crash involved at least one driver who was 16 or 17 years old.",
      "<i>DRIVER65PLUS:</i> Crash involved at least one driver who was at least 65 years old.",
      "<i>PCTBACHMOR:</i> % of individuals 25 years of age or older who have at least a bachelorâ€™s degree.",
      "<i>MEDHHINC:</i> Median household income."
    ),
    general_title = "Variable Definitions:",
    footnote_as_chunk = FALSE, 
    escape = FALSE # To allow HTML formatting.
  )
  
  # Highlight significant p-values.
  #row_spec(which(reduced_logit_results[, "Pr(>|z|)"] < 0.05), bold = T)

full_model

# Save as HTML file.
#save_kable(full_model, "full_model.html", zoom = 3, self_contained = TRUE)

# Then convert HTML to PNG using webshot.
#webshot::webshot("full_model.html", "full_model.png")
```

*3.a.ii.* For each predictor, also compute the odds ratio and the 95% confidence interval (CI) using commands shown in the slides. Use the syntax presented on the slide titled â€˜Merging Odds Ratios to ð›½ Coefficients in Râ€™ to merge the odds ratios and CIs to the matrix that contains coefficients and p-values. Present the resulting (merged) matrix in your report.

```{r odds ratios}
coefs <- summary(logit_full)$coefficients
OR <- exp(coef(logit_full))
lower <- exp(coef(logit_full) - 1.96 * coefs[, "Std. Error"])
upper <- exp(coef(logit_full) + 1.96 * coefs[, "Std. Error"])

merged <- cbind(coefs, OR, lower, upper)

kable(merged, digits = 3)
```

*3.a.iii.* Using the syntax presented in the slides, calculate the sensitivity, specificity and misclassification rate for each of the following cut-off values: **0.02; 0.03; 0.05; 0.07; 0.08; 0.09; 0.10; 0.15; 0.20; 0.50** and present them in a table. In the table, highlight the cut-off value which has the lowest misclassification rate.

```{r sensitivity specificity misclassification}
cutoffs <- c(0.02, 0.03, 0.05, 0.07, 0.08, 0.09, 0.10, 0.15, 0.20, 0.50)

phat <- logit_full$fitted.values
y <- cdc_data$DRINKING_D

cutoff_table <- data.frame(
  Cutoff = cutoffs,
  Sensitivity = NA,
  Specificity = NA,
  Misclass = NA
)

for (i in seq_along(cutoffs)) {
  
  c <- cutoffs[i]
  pred <- ifelse(phat >= c, 1, 0)
  
  TP <- sum(pred == 1 & y == 1)
  TN <- sum(pred == 0 & y == 0)
  FP <- sum(pred == 1 & y == 0)
  FN <- sum(pred == 0 & y == 1)
  
  cutoff_table$Sensitivity[i] <- TP/(TP+FN)
  cutoff_table$Specificity[i] <- TN/(TN+FP)
  cutoff_table$Misclass[i] <- (FP+FN)/length(y)
}

kable(
  cutoff_table,
  digits = 3,
  caption = "Sensitivity, Specificity, and Misclassification Across Cutoffs"
)
```

: Sensitivity, Specificity, and Misclassification Table

*3.a.iv.* Using the syntax presented in the slides, generate the ROC curve, and identify the optimal cut-off value. Be sure to export the image of the ROC curve (as you will be expected to present it in your report).

```{r ROC curve}
library(pROC)
library(ggplot2)

# Create ROC object
roc_obj <- roc(y, phat)

# Get AUC
auc_value <- auc(roc_obj)

# Plot with ggplot
roc_curve <- ggroc(roc_obj, color = "#0072B2", size = 1.2) +
  geom_abline(intercept = 1, slope = 1, linetype = "dashed", color = "gray50") +
  annotate("text", x = 0.25, y = 0.25, 
           label = paste("AUC =", round(auc_value, 3)), 
           size = 5, fontface = "bold") +
  labs(
    title = "ROC Curve",
    x = "Specificity",
    y = "Sensitivity"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.grid.minor = element_blank()
  )

roc_curve

ggsave("roc_curve.png", roc_curve, height = 6, width = 6, dpi = 300)
```

*3.a.v.* Using the syntax presented in the slides, calculate the area under the ROC curve.

*3.b.* Re-run the model without the `PCTBACHMOR` and `MEDHHINC` terms. As in *3.a.i* and *3.a.ii* above, use the summary command to examine results, and calculate the odds ratio and the 95% confidence interval for each predictor. As in *3.a.ii* above, merge the odds ratios and confidence intervals to the matrix containing coefficients and p-values. Present the resulting (merged) matrix in your report.

```{r reduced model 3.b}
logit_reduced <- glm(DRINKING_D ~
                       FATAL_OR_M + OVERTURNED + CELL_PHONE +
                       SPEEDING + AGGRESSIVE + DRIVER1617 + DRIVER65PLUS,
                     data = cdc_data,
                     family = binomial
                     )

summary(logit_reduced)

reduced_coefs <- summary(logit_reduced)$coefficients
OR2 <- exp(coef(logit_reduced))
CI2 <- exp(confint(logit_reduced))

reduced_logit_results <- cbind(
  reduced_coefs,
  OR = OR2,
  CI_low = CI2[,1],
  CI_high = CI2[,2]
)

# Create table.
reduced_model <- kbl(reduced_logit_results, 
    digits = 2,
    # Rename columns.
    col.names = c("Estimate", "Standard Error", "Z-Value", "P-Value", "Odds Ratio", "2.5% CI", "97.5% CI"),
    align = "c",
    caption = "Reduced Logistic Regression Model (Binary Predictors)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F) %>%
  column_spec(1, bold = T) %>%
  footnote(
    general = c(
      "<i>FATAL_OR_M:</i> Crash resulted in fatality or major injury.",
      "<i>OVERTURNED:</i> Crash involved an overturned vehicle.",
      "<i>CELL_PHONE:</i> Driver was using cell phone.",
      "<i>SPEEDING:</i> Crash involved speeding car.",
      "<i>AGGRESSIVE:</i> Crash involved aggressive driving.",
      "<i>DRIVER1617:</i> Crash involved at least one driver who was 16 or 17 years old.",
      "<i>DRIVER65PLUS:</i> Crash involved at least one driver who was at least 65 years old."
    ),
    general_title = "Variable Definitions:",
    footnote_as_chunk = FALSE, 
    escape = FALSE # To allow HTML formatting.
  )
  
  # Highlight significant p-values.
  #row_spec(which(reduced_logit_results[, "Pr(>|z|)"] < 0.05), bold = T)

# Save as HTML file.
#save_kable(reduced_model, "reduced_model.html", zoom = 3, self_contained = TRUE)

# Then convert HTML to PNG using webshot.
#webshot::webshot("reduced_model.html", "reduced_model.png")
```

*3.c.* Compare the two models using the Akaike Information Criterion (AIC). The results are typically presented at the bottom of the logistic regression output. They may also be obtained using the `AIC` command. For instance, if the results obtained from the `glm` command for the first model are saved as `mylogit1` and the results from the second model are saved as `mylogit2`, the R syntax to obtain the AICs from both models would be `AIC(mylogit1, mylogit2)`. Here, recall that lower values of the AIC correspond to a better model.

```{r compare models}
AIC(logit_full, logit_reduced)
```

```{r cross-tabulation-table 2.b.iv.3}

# Split data into No Alcohol and Alcohol.
no_alcohol <- subset(binary_summary, DRINKING_D == "No Alcohol")
alcohol <- subset(binary_summary, DRINKING_D == "Alcohol")

# Create a wide dataframe with one row per predictor.
# Extract the counts and percents from alcohol categories.
wide_summary <- data.frame(
  Predictor = no_alcohol$Predictor,
  N_No = no_alcohol$Count_1,
  Pct_No = no_alcohol$Percent_1,
  N_Yes = alcohol$Count_1,
  Pct_Yes = alcohol$Percent_1,
  Total = no_alcohol$Total_1 
)

# Merge with the Chi-Square P-Values.
final_table_data <- merge(wide_summary, chi_results[, c("Predictor", "p_value")], 
                          by = "Predictor")

# Re-order rows to match original predictor list.
final_table_data <- final_table_data[match(predictors, final_table_data$Predictor), ]

# Create table.
cross_tab <- kbl(final_table_data, 
    col.names = c("Predictor", "N", "%", "N", "%", "Total", "Î§2 p-value"),
    align = c("l", "c", "c", "c", "c", "c", "c"),
    digits = 2,
    row.names = FALSE,
    format.args = list(big.mark = ","),
    caption = "Cross-Tabulation of Predictors by Alcohol Involvement") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>%
  add_header_above(c(" " = 1, "No Alcohol Involved\n(DRINKING_D = 0)" = 2, "Alcohol Involved\n(DRINKING_D = 1)" = 2, " " = 2)) %>%
  column_spec(1, bold = TRUE) %>%
  footnote(
    general = c(
      "<i>FATAL_OR_M:</i> Crash resulted in fatality or major injury.",
      "<i>OVERTURNED:</i> Crash involved an overturned vehicle.",
      "<i>CELL_PHONE:</i> Driver was using cell phone.",
      "<i>SPEEDING:</i> Crash involved speeding car.",
      "<i>AGGRESSIVE:</i> Crash involved aggressive driving.",
      "<i>DRIVER1617:</i> Crash involved at least one driver who was 16 or 17 years old.",
      "<i>DRIVER65PLUS:</i> Crash involved at least one driver who was at least 65 years old."
    ),
    general_title = "Variable Definitions:",
    footnote_as_chunk = FALSE, 
    escape = FALSE # To allow HTML formatting.
  )

cross_tab

# Save as HTML file.
#save_kable(cross_tab, "cross_tabulation_table.html", zoom = 3, self_contained = TRUE)

# Then convert HTML to PNG using webshot.
#webshot::webshot("cross_tabulation_table.html", "cross_tabulation_table.png")
```

```{r means-t-test-table 2.c.iii.3}
# Split the data into groups.
no_alcohol_means <- subset(mean_sd_table, Group == "No Alcohol")
alcohol_means    <- subset(mean_sd_table, Group == "Alcohol")

# Make wide.
wide_means <- data.frame(
  Predictor = no_alcohol_means$Predictor,
  Mean_No   = no_alcohol_means$Mean,
  SD_No     = no_alcohol_means$SD,
  Mean_Yes  = alcohol_means$Mean,
  SD_Yes    = alcohol_means$SD
)

# Merge with t-test results to get the p-value.
final_means_data <- merge(wide_means, t_table[, c("Predictor", "p_value")], by = "Predictor")

# Create table.
means_of_predictors <- kbl(final_means_data, 
    col.names = c("Predictor", "Mean", "SD", "Mean", "SD", "t-test p-value"),
    align = c("l", "c", "c", "c", "c", "c"),
    digits = 2,
    row.names = FALSE,
    format.args = list(big.mark = ","),
    caption = "Means of Predictors by Alcohol Involvement") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F) %>%
  add_header_above(c(" " = 1, "No Alcohol Involved\n(DRINKING_D = 0)" = 2, "Alcohol Involved\n(DRINKING_D = 1)" = 2, " " = 1)) %>%
  column_spec(1, bold = T) %>%
  footnote(
    general = c(
      "<i>PCTBACHMOR:</i> % with bachelor's degree or more.",
      "<i>MEDHHINC:</i> Median household income."
    ),
    general_title = "Variable Definitions:",
    footnote_as_chunk = FALSE, 
    escape = FALSE
  )

means_of_predictors

# Save as HTML file.
#save_kable(means_of_predictors, "means_of_predictors.html", zoom = 3, self_contained = TRUE)

# Then convert HTML to PNG using webshot.
#webshot::webshot("means_of_predictors.html", "means_of_predictors.png")
```

```{r sensitivity specificity table 3.a.iii}
# Find the index of the row with the minimum misclassification rate.
best_row <- which.min(cutoff_table$Misclass)

cutoff_table <- kbl(cutoff_table, 
    digits = 2,
    caption = "Sensitivity, Specificity, and Misclassification Rates") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F) %>%
  # Bold best row.
  row_spec(best_row, bold = TRUE, color = "black")

cutoff_table

# Save as HTML file.
#save_kable(cutoff_table, "cutoff_table.html", zoom = 3, self_contained = TRUE)

# Then convert HTML to PNG using webshot.
#webshot::webshot("cutoff_table.html", "cutoff_table.png")
```

```{r aic 3.c}
# Calculate AIC for both models
aic_values <- AIC(logit_full, logit_reduced)

# The AIC() function returns a dataframe with row names as the models.
# Let's pretty it up for the table.
aic_table <- data.frame(
  Model = c("Full Model (All Predictors)", "Reduced Model (Binary Only)"),
  df    = aic_values$df,
  AIC   = aic_values$AIC
)

aic_kable <- kbl(aic_table, 
    digits = 2,
    col.names = c("Model", "Degrees of Freedom", "AIC"),
    align = c("l", "c", "c"),
    caption = "Model Comparison: Akaike Information Criterion (AIC)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F) %>%
  row_spec(which.min(aic_table$AIC), bold = T, color = "black") %>%
  footnote(
    general = c(
      "Lower AIC is better."
    ),
    general_title = "Note:",
    footnote_as_chunk = FALSE, 
    escape = FALSE
  )
  

aic_kable

# Save as HTML file.
#save_kable(aic_kable, "aic_kable.html", zoom = 3, self_contained = TRUE)

# Then convert HTML to PNG using webshot.
#webshot::webshot("aic_kable.html", "aic_kable.png")
```